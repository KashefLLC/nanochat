{
    "model": "baseline_d12",
    "config": {
        "depth": 12,
        "n_embd": 768,
        "n_head": 6,
        "n_kv_head": 6,
        "n_layer": 12,
        "sequence_len": 2048,
        "vocab_size": 32768,
        "window_pattern": "SSSL"
    },
    "parameters": {
        "wte": 25165824,
        "value_embeds": 150994944,
        "lm_head": 25165824,
        "transformer_matrices": 84935808,
        "scalars": 24,
        "total": 286262424
    },
    "training": {
        "total_steps": 2205,
        "total_tokens": 1156055040,
        "tokens_to_params_ratio": 10.5,
        "total_batch_size": 524288,
        "device_batch_size": 4,
        "grad_accum_steps": 64,
        "training_time_minutes": 1051.73,
        "peak_vram_mb": 6864.23,
        "avg_tokens_per_sec": 34500,
        "bf16_mfu_percent": 39.0,
        "flops_estimate": "9.273498e+17",
        "epochs": 5
    },
    "validation_bpb": {
        "step_0000": 3.174815,
        "step_0250": 1.134484,
        "step_0500": 1.050475,
        "step_0750": 1.018844,
        "step_1000": 1.004585,
        "step_1250": 0.992547,
        "step_1500": 0.978592,
        "step_1750": 0.971917,
        "step_2000": 0.966843,
        "step_2205": 0.965153,
        "minimum": 0.965153
    },
    "core_metric": {
        "step_1000": 0.0883,
        "step_2000": 0.1136,
        "step_2205": 0.1121
    },
    "final_training_loss": 2.750421,
    "checkpoint_path": "/home/para2x/.cache/nanochat/base_checkpoints/d12/model_002205.pt",
    "hardware": {
        "gpu": "NVIDIA GeForce RTX 3090",
        "vram_gb": 24.576,
        "cuda_version": "12.8",
        "pytorch_version": "2.9.1+cu128",
        "flash_attention": "SDPA (FA3 not available on Ampere)"
    }
}
